{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15bb6375",
   "metadata": {},
   "source": [
    "# HW1_DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb82d6d8",
   "metadata": {},
   "source": [
    "## Importing libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e30839b3-8c46-4082-baa1-3e249f91edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from pprint import pprint\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcce383-33ab-4b4a-aaac-e026ae30f993",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc19de8b-3a41-4ca6-8e37-0908fe4ca12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"nursery.csv\")                         # importing dataset with pandas\n",
    "df = df.rename(columns={\"final evaluation\": \"label\"})   # renaming last column as \"label\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "763c3891-cc2e-4dc3-a788-6e18cf6870df",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = df.columns                                     # collecting all the features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef4201a5-ae00-48b7-bb03-456858957cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parents</th>\n",
       "      <th>has_nurs</th>\n",
       "      <th>form</th>\n",
       "      <th>children</th>\n",
       "      <th>housing</th>\n",
       "      <th>finance</th>\n",
       "      <th>social</th>\n",
       "      <th>health</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parents has_nurs      form children     housing     finance         social  \\\n",
       "0   usual   proper  complete        1  convenient  convenient        nonprob   \n",
       "1   usual   proper  complete        1  convenient  convenient        nonprob   \n",
       "2   usual   proper  complete        1  convenient  convenient        nonprob   \n",
       "3   usual   proper  complete        1  convenient  convenient  slightly_prob   \n",
       "4   usual   proper  complete        1  convenient  convenient  slightly_prob   \n",
       "\n",
       "        health      label  \n",
       "0  recommended  recommend  \n",
       "1     priority   priority  \n",
       "2    not_recom  not_recom  \n",
       "3  recommended  recommend  \n",
       "4     priority   priority  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()                                               # showing the first 5 rows of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47295872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12960 entries, 0 to 12959\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   parents   12960 non-null  object\n",
      " 1   has_nurs  12960 non-null  object\n",
      " 2   form      12960 non-null  object\n",
      " 3   children  12960 non-null  object\n",
      " 4   housing   12960 non-null  object\n",
      " 5   finance   12960 non-null  object\n",
      " 6   social    12960 non-null  object\n",
      " 7   health    12960 non-null  object\n",
      " 8   label     12960 non-null  object\n",
      "dtypes: object(9)\n",
      "memory usage: 911.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()                                              # more information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc964315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parents</th>\n",
       "      <th>has_nurs</th>\n",
       "      <th>form</th>\n",
       "      <th>children</th>\n",
       "      <th>housing</th>\n",
       "      <th>finance</th>\n",
       "      <th>social</th>\n",
       "      <th>health</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4320</td>\n",
       "      <td>2592</td>\n",
       "      <td>3240</td>\n",
       "      <td>3240</td>\n",
       "      <td>4320</td>\n",
       "      <td>6480</td>\n",
       "      <td>4320</td>\n",
       "      <td>4320</td>\n",
       "      <td>4320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       parents has_nurs      form children     housing     finance   social  \\\n",
       "count    12960    12960     12960    12960       12960       12960    12960   \n",
       "unique       3        5         4        4           3           2        3   \n",
       "top      usual   proper  complete        1  convenient  convenient  nonprob   \n",
       "freq      4320     2592      3240     3240        4320        6480     4320   \n",
       "\n",
       "             health      label  \n",
       "count         12960      12960  \n",
       "unique            3          5  \n",
       "top     recommended  not_recom  \n",
       "freq           4320       4320  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()                                          # more information about the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29351790-7f88-4b58-aa01-231d103bd1ae",
   "metadata": {},
   "source": [
    "## Split Dataset to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36c6896e-f7a6-443a-a082-875d5aa39404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, test_size):\n",
    "    \"\"\" Splits the dataset(df) to train and test with the number/pertentage of test dataset. \"\"\"\n",
    "    \n",
    "    if isinstance(test_size, float):                                   # if test size is proportion (%)\n",
    "        test_size = round(test_size * len(df))\n",
    "\n",
    "    indices = df.index.tolist()                                        # all the indexes\n",
    "    test_indices = random.sample(population=indices, k=test_size)      # choosing randomly the indicies for test\n",
    "\n",
    "    test_df = df.loc[test_indices]                                     # collecting the test dataset        \n",
    "    train_df = df.drop(test_indices)                                   # drop test dataset for making train dataset\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f662aaf9-2bb6-4658-92f2-c473f1108d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)                                              # initialize the random number generator\n",
    "train_df, test_df = train_test_split(df, test_size=0.25)    # collect 20% of dataset for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5192fb93-1bdb-42ee-8b40-91b85b98ed30",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_df.to_numpy()                                  # tranforming dataset to numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65541d42",
   "metadata": {},
   "source": [
    "## Entropy & Gini Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3536e0-e286-4be1-9239-5b82e64a4def",
   "metadata": {},
   "source": [
    "$$E(S)=\\sum_{i=1}^{c} âˆ’p_i log_2p_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c9beaf4-f623-46aa-a3a8-f83f5a5471da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(labels):\n",
    "    \"\"\" Computes entropy of label distribution. \"\"\"\n",
    "\n",
    "    n_labels = len(labels)                                   # number of data \n",
    "\n",
    "    if n_labels <= 1:\n",
    "        return 0\n",
    "\n",
    "    value, counts = np.unique(labels, return_counts=True)    # unique classes & number of data in label\n",
    "    probs = counts / n_labels                                # probability of each class\n",
    "    n_classes = np.count_nonzero(probs)                      # number of classes in label   \n",
    "\n",
    "    if n_classes <= 1:                                      \n",
    "        return 0\n",
    "\n",
    "    ent = 0.\n",
    "\n",
    "    # Compute entropy\n",
    "    for i in probs:                                         # compute entropy using  \n",
    "        ent -= i * np.log2(i)                               # probabilities of each class and log2\n",
    "\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cef3f7-7c9e-418a-8606-c75290c4bf9b",
   "metadata": {},
   "source": [
    "$$Gini=1 - \\sum_{i=1}^{c} (p_i)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c5d02d44-663c-41ca-a5fb-b96c97861ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(labels):\n",
    "    \"\"\"\n",
    "    Given the Series, it calculates the Gini Impurity. \n",
    "    y: variable with which calculate Gini Impurity.\n",
    "    \"\"\"\n",
    "    unique, counts = np.unique(labels, return_counts=True)  # unique classes & number of data in label\n",
    "    p = counts / labels.shape[0]                            # probability of each class\n",
    "    gini = 1 - np.sum(p**2)                                 # calculate gini for each class using formula\n",
    "    \n",
    "    return (gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e36a245",
   "metadata": {},
   "source": [
    "## Split the data at the node into left and right branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c878c6a-d4b3-4faf-9db8-d5283a38107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, node_indices, feature):\n",
    "    \"\"\"\n",
    "    Splits the data at the given node into\n",
    "    left and right branches\n",
    "    \n",
    "    Args:\n",
    "        X (ndarray):             Data matrix of shape(n_samples, n_features)\n",
    "        node_indices (ndarray):  List containing the active indices. I.e, the samples being considered at this step.\n",
    "        feature (int):           Index of feature to split on\n",
    "    \n",
    "    Returns:\n",
    "        result (dict): Indices with feature value\n",
    "    \"\"\"\n",
    "    result = dict()\n",
    "    for value in set(X[:, feature]):            # building the output dictionary for each feature\n",
    "        result[str(value)] = []\n",
    "\n",
    "    for i in node_indices:                      # appending the active indices to the dictionary\n",
    "        result[X[i, feature]].append(i)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4c360b",
   "metadata": {},
   "source": [
    "## Information gain of the node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e527fd11-185b-4d0e-86c0-222583c5b14c",
   "metadata": {},
   "source": [
    "This metric indicates the improvement when making different partitions and is usually used with entropy (it could also be used with the Gini index, although in that case it would not be called Informaiton Gain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55720e63-c8ca-4ba6-98df-b3c971b95c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_information_gain(X, y, node_indices, feature, impurity_func=gini):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute the information of splitting the node on a given feature\n",
    "    \n",
    "    Args:\n",
    "        X (ndarray):            Data matrix of shape(n_samples, n_features)\n",
    "        y (array like):         list or ndarray with n_samples containing the target variable\n",
    "        node_indices (ndarray): List containing the active indices. I.e, the samples being considered in this step.\n",
    "   \n",
    "    Returns:\n",
    "        cost (float):        Cost computed\n",
    "    \n",
    "    \"\"\"    \n",
    "\n",
    "    # Split dataset\n",
    "    splited = split_dataset(X, node_indices, feature)\n",
    "    \n",
    "    # Some useful variables\n",
    "    X_node, y_node = X[node_indices], y[node_indices]\n",
    "    n = len(y_node)  \n",
    "    \n",
    "    if n == 0:\n",
    "        return 0\n",
    "    \n",
    "    information_gain = 0                                                    # initializing variables\n",
    "    conditional_impurity = 0\n",
    "    \n",
    "    for key, value in splited.items():                                      # calculating conditional entropy for each class\n",
    "        conditional_impurity += (impurity_func(y[value]) * (len(value) / n))\n",
    "    \n",
    "    information_gain = impurity_func(y_node) - conditional_impurity          # calculating information gain using formula\n",
    "    \n",
    "    return information_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2666cb",
   "metadata": {},
   "source": [
    "## Best feature to split the node data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa4ea5e2-e0d9-4857-8307-19e541c65ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_split(X, y, node_indices, used_feature, impurity_func):   \n",
    "    \"\"\"\n",
    "    Returns the optimal feature and threshold value\n",
    "    to split the node data \n",
    "    \n",
    "    Args:\n",
    "        X (ndarray):            Data matrix of shape(n_samples, n_features)\n",
    "        y (array like):         list or ndarray with n_samples containing the target variable\n",
    "        node_indices (ndarray): List containing the active indices. I.e, the samples being considered in this step.\n",
    "\n",
    "    Returns:\n",
    "        best_feature (int):     The index of the best feature to split\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Some useful variables\n",
    "    num_features = X.shape[1]\n",
    "    best_feature = -1                                                               # initializing variables\n",
    "    max_info_gain = 0\n",
    "    \n",
    "    for feature in range(num_features):                                             # finding the maximum information gain\n",
    "        if feature in used_feature:\n",
    "            continue\n",
    "        info_gain = compute_information_gain(X, y, node_indices, feature=feature, impurity_func=impurity_func)\n",
    "        if (info_gain >= max_info_gain):\n",
    "            max_info_gain = info_gain\n",
    "            best_feature = feature    \n",
    "   \n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6619dc72",
   "metadata": {},
   "source": [
    "## Tree algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b52514a-2746-4b55-93a1-760c0a4d353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree_recursive(data, node_indices, used_feature, branch_name, max_depth, current_depth, impurity_func=entropy):\n",
    "    \"\"\"\n",
    "    Build a tree using the recursive algorithm that split the dataset into 2 subgroups at each node.\n",
    "    \n",
    "    \n",
    "    Args:\n",
    "        X (ndarray):            Data matrix of shape(n_samples, n_features)\n",
    "        y (array like):         list or ndarray with n_samples containing the target variable\n",
    "        node_indices (ndarray): List containing the active indices. I.e, the samples being considered in this step.\n",
    "        branch_name (string):   Name of the branch. ['Root', 'Left', 'Right']\n",
    "        max_depth (int):        Max depth of the resulting tree. \n",
    "        current_depth (int):    Current depth. Parameter used during recursive call.\n",
    "   \n",
    "    \"\"\" \n",
    "    X = data[:, :-1]                            # dataset \n",
    "    y = data[:, -1]                             # target\n",
    "    \n",
    "    formatting = \"-\"*current_depth\n",
    "    \n",
    "    # if y had only one class \n",
    "    if len(set(y[node_indices])) == 1:\n",
    "        return y[node_indices[0]]\n",
    "    \n",
    "    # Maximum depth reached - stop splitting\n",
    "    if current_depth == max_depth:\n",
    "        value, counts = np.unique(y[node_indices], return_counts=True)\n",
    "        formatting = \" \"*current_depth + \"-\"*current_depth\n",
    "        if len(counts) == 0:\n",
    "            return\n",
    "        return value[np.argmax(counts)]\n",
    "    \n",
    "    \n",
    "\n",
    "    # Otherwise, get best split and split the data\n",
    "    # Get the best feature and threshold at this node\n",
    "    best_feature = get_best_split(X, y, node_indices, used_feature, impurity_func) \n",
    "    used_feature.append(best_feature)\n",
    "    formatting = \"-\"*current_depth\n",
    "#     print(\"%s Depth %d, %s: Split on feature: %s\" % (formatting, current_depth, branch_name, header[best_feature]))\n",
    "    \n",
    "    # Split the dataset at the best feature\n",
    "    splited = split_dataset(X, node_indices, best_feature)\n",
    "    \n",
    "    feature_name = header[best_feature]\n",
    "    question = \"{}\".format(feature_name)\n",
    "\n",
    "    # instantiate sub-tree\n",
    "    sub_tree = {question: []}\n",
    "\n",
    "    for feature, indices in splited.items():\n",
    "        used_feature_copy = used_feature.copy()\n",
    "        branch = build_tree_recursive(data, indices, used_feature_copy, feature, max_depth, current_depth+1)\n",
    "        sub_tree[question].append({feature: branch})\n",
    "\n",
    "    return sub_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2769432b-0866-4834-946c-8b40026ee3db",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d5ec0727-3943-404f-8a4b-9146fc05bf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(df, tree):\n",
    "    af = {}\n",
    "    af[\"classification\"] = df.apply(classify_example, axis=1, args=(tree,))\n",
    "    af[\"classification_correct\"] = af[\"classification\"] == df[\"label\"]\n",
    "    accuracy = af[\"classification_correct\"].mean()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6a72b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Classify an example using the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a068896-aab9-453c-80a8-b8e70aa1565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_example(example, tree):\n",
    "    \n",
    "    question = list(tree.keys())[0]\n",
    "    values = tree[question]\n",
    "\n",
    "    i = 0\n",
    "    for value in values:\n",
    "        name_of_value = list(value.keys())[0]\n",
    "        \n",
    "        if str(example[question]) == name_of_value:\n",
    "            answer = list(tree[question][i].values())[0]\n",
    "            \n",
    "        i += 1\n",
    "\n",
    "    # base case\n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    \n",
    "    # recursive part\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return classify_example(example, residual_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1721a337-267a-48b3-8175-28260c35871b",
   "metadata": {},
   "source": [
    "## Assemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "84aad0a6-cf48-4088-8580-d34ae29c8bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df, train_size, max_depth, impurity_func):\n",
    "    train_df, test_df = train_test_split(df, test_size=1-train_size)\n",
    "    data = train_df.to_numpy() \n",
    "    root_indices = range(data.shape[0])\n",
    "    used_feature = []\n",
    "    tree = build_tree_recursive(data, root_indices, used_feature, \"Root\", max_depth=max_depth, current_depth=0, impurity_func=impurity_func)\n",
    "    return train_df, test_df, tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d2be2cd5-fc24-4722-b709-bd39f030c4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question(df, train_size, max_depth):\n",
    "    train_df, test_df, tree = train(df, train_size, max_depth, entropy)\n",
    "    with open(f'results/result{train_size*100}-{max_depth}-entrpoy.yml', 'w') as f:\n",
    "        yaml.dump(tree, f)\n",
    "    print(\"Entropy\")\n",
    "    print(f\"Accuracy on total: {calculate_accuracy(df, tree)}\")\n",
    "    print(f\"Accuracy on train: {calculate_accuracy(train_df, tree)}\")\n",
    "    print(f\"Accuracy on test: {calculate_accuracy(test_df, tree)}\")\n",
    "    \n",
    "    train_df, test_df, tree = train(df, train_size, max_depth, gini)\n",
    "    with open(f'results/result{train_size*100}-{max_depth}-gini.yml', 'w') as f:\n",
    "        yaml.dump(tree, f)\n",
    "    print(\"Gini\")\n",
    "    print(f\"Accuracy on total: {calculate_accuracy(df, tree)}\")\n",
    "    print(f\"Accuracy on train: {calculate_accuracy(train_df, tree)}\")\n",
    "    print(f\"Accuracy on test: {calculate_accuracy(test_df, tree)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3574dda-8f26-4bcd-b15d-0517600686b1",
   "metadata": {},
   "source": [
    "# Use model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639259e5",
   "metadata": {},
   "source": [
    "## a) Train: 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a7ef98a2-37e0-494d-a723-6317ba1a8acf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df, test_df, tree = train(df, 0.8, 3, gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "809c4918-7273-4492-812a-1663fa8bb259",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'health': [{'priority': {'has_nurs': [{'critical': {'parents': [{'pretentious': 'spec_prior'},\n",
      "                                                                 {'great_pret': 'spec_prior'},\n",
      "                                                                 {'usual': 'spec_prior'}]}},\n",
      "                                       {'less_proper': {'parents': [{'pretentious': 'priority'},\n",
      "                                                                    {'great_pret': 'spec_prior'},\n",
      "                                                                    {'usual': 'priority'}]}},\n",
      "                                       {'improper': {'parents': [{'pretentious': 'spec_prior'},\n",
      "                                                                 {'great_pret': 'spec_prior'},\n",
      "                                                                 {'usual': 'priority'}]}},\n",
      "                                       {'very_crit': {'children': [{'2': 'spec_prior'},\n",
      "                                                                   {'1': 'spec_prior'},\n",
      "                                                                   {'more': 'spec_prior'},\n",
      "                                                                   {'3': 'spec_prior'}]}},\n",
      "                                       {'proper': {'parents': [{'pretentious': 'priority'},\n",
      "                                                               {'great_pret': 'spec_prior'},\n",
      "                                                               {'usual': 'priority'}]}}]}},\n",
      "            {'not_recom': 'not_recom'},\n",
      "            {'recommended': {'has_nurs': [{'critical': {'parents': [{'pretentious': 'spec_prior'},\n",
      "                                                                    {'great_pret': 'spec_prior'},\n",
      "                                                                    {'usual': 'priority'}]}},\n",
      "                                          {'less_proper': {'social': [{'slightly_prob': 'priority'},\n",
      "                                                                      {'problematic': 'priority'},\n",
      "                                                                      {'nonprob': 'priority'}]}},\n",
      "                                          {'improper': {'parents': [{'pretentious': 'priority'},\n",
      "                                                                    {'great_pret': 'spec_prior'},\n",
      "                                                                    {'usual': 'priority'}]}},\n",
      "                                          {'very_crit': {'social': [{'slightly_prob': 'spec_prior'},\n",
      "                                                                    {'problematic': 'spec_prior'},\n",
      "                                                                    {'nonprob': 'spec_prior'}]}},\n",
      "                                          {'proper': {'parents': [{'pretentious': 'priority'},\n",
      "                                                                  {'great_pret': 'priority'},\n",
      "                                                                  {'usual': 'priority'}]}}]}}]}\n"
     ]
    }
   ],
   "source": [
    "pprint(tree, width=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6f727d15-a46d-465a-9d6e-13c678ec53a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8915895061728395\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {calculate_accuracy(train_df, tree)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a9ef8ce3-0a94-4b0d-a7c7-34d4730888d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parents             usual\n",
       "has_nurs         critical\n",
       "form               foster\n",
       "children                2\n",
       "housing          critical\n",
       "finance            inconv\n",
       "social      slightly_prob\n",
       "health          not_recom\n",
       "label           not_recom\n",
       "Name: 3344, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = test_df.iloc[0]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6b4711d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'not_recom'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_example(example, tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60338870-7830-4614-a9ba-6f4b5f32afa2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## b-1) Train: 75%, max_depth = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6f67479-d061-4b45-b41c-3a83fe43b025",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy\n",
      "Accuracy on total: 0.9732253086419753\n",
      "Accuracy on train: 0.976440329218107\n",
      "Accuracy on test: 0.9635802469135802\n",
      "Gini\n",
      "Accuracy on total: 0.9738425925925925\n",
      "Accuracy on train: 0.9775720164609053\n",
      "Accuracy on test: 0.9626543209876544\n"
     ]
    }
   ],
   "source": [
    "question(df, train_size=0.75, max_depth=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83698dd-ace7-4ea5-955c-5604dd690068",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## b-2) Train: 75%, max_depth = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "954ddf65-6695-4772-8191-dc3f50285671",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy\n",
      "Accuracy on total: 0.9929783950617284\n",
      "Accuracy on train: 1.0\n",
      "Accuracy on test: 0.9719135802469135\n",
      "Gini\n",
      "Accuracy on total: 0.9944444444444445\n",
      "Accuracy on train: 1.0\n",
      "Accuracy on test: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "question(df, train_size=0.75, max_depth=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44a220c-fea5-4003-b40f-4a36e82edcfc",
   "metadata": {},
   "source": [
    "## c-1) Train: 50%, max_depth = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33e3ccb5-b47d-4ed8-b14c-f2d5a1e1255a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy\n",
      "Accuracy on total: 0.9655092592592592\n",
      "Accuracy on train: 0.9783950617283951\n",
      "Accuracy on test: 0.9526234567901235\n",
      "Gini\n",
      "Accuracy on total: 0.9678240740740741\n",
      "Accuracy on train: 0.9796296296296296\n",
      "Accuracy on test: 0.9560185185185185\n"
     ]
    }
   ],
   "source": [
    "question(df, train_size=0.5, max_depth=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54441cd-7b96-439d-b0b4-a0a37f9b94cf",
   "metadata": {},
   "source": [
    "## c-2) Train: 50%, max_depth = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bc506ceb-5a03-4642-b3f6-b2c3706edd99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy\n",
      "Accuracy on total: 0.9790123456790123\n",
      "Accuracy on train: 1.0\n",
      "Accuracy on test: 0.9580246913580247\n",
      "Gini\n",
      "Accuracy on total: 0.9786265432098765\n",
      "Accuracy on train: 1.0\n",
      "Accuracy on test: 0.957253086419753\n"
     ]
    }
   ],
   "source": [
    "question(df, train_size=0.5, max_depth=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
